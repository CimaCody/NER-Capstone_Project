{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxlhJtf0A22L"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_upsample_corpus(task_file_path, upsample_factor=2):\n",
        "    \"\"\"Load the task-level corpus and upsample it by repeating its contents.\"\"\"\n",
        "    with open(task_file_path, 'r', encoding='utf-8') as file:\n",
        "        task_data = file.read()\n",
        "    upsampled_task_data = task_data * upsample_factor\n",
        "    return upsampled_task_data\n",
        "\n",
        "def combine_corpora(entity_file_path, upsampled_task_data):\n",
        "    \"\"\"Load the entity-level corpus and append the upsampled task-level corpus.\"\"\"\n",
        "    with open(entity_file_path, 'r', encoding='utf-8') as file:\n",
        "        entity_data = file.read()\n",
        "    combined_data = entity_data + '\\n' + upsampled_task_data\n",
        "    return combined_data"
      ],
      "metadata": {
        "id": "MH7ylc7cBAr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your corpus files\n",
        "task_file_path = '/content/drive/MyDrive/Capstone Project Data/Task-Level Corpora/Joined Task-Level.txt'\n",
        "entity_file_path = '/content/drive/MyDrive/Capstone Project Data/Entity-Level Corpora/Joined Entity-Level.txt'\n",
        "output_file_path = '/content/drive/MyDrive/Capstone Project Data/DAPT Dataset/Combined_Corpus.txt'"
      ],
      "metadata": {
        "id": "QQSU7sMhDYI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_combined_corpus(combined_data, output_file_path):\n",
        "    \"\"\"Save the combined corpus to a new file.\"\"\"\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "        file.write(combined_data)"
      ],
      "metadata": {
        "id": "lSpLXBs2DcK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the corpora\n",
        "upsampled_task_data = load_and_upsample_corpus(task_file_path)\n",
        "combined_data = combine_corpora(entity_file_path, upsampled_task_data)\n",
        "save_combined_corpus(combined_data, output_file_path)\n",
        "\n",
        "print(\"Combined corpus saved successfully.\")"
      ],
      "metadata": {
        "id": "iv3GQ88PBAiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WI3iJD21BAfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VAGApa2rBAco"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}