{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from torch.optim import AdamW\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertForTokenClassification, BertTokenizerFast\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "wSzbGwcfdWe5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55mb_kWvb4nU",
        "outputId": "f64b15d1-60e5-4396-a72f-93046d2ddfe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    'O': 0,\n",
        "    'B-product': 1, 'I-product': 2,\n",
        "    'B-field': 3, 'I-field': 4,\n",
        "    'B-task': 5, 'I-task': 6,\n",
        "    'B-researcher': 7, 'I-researcher': 8,\n",
        "    'B-country': 9, 'I-country': 10,\n",
        "    'B-politician': 11, 'I-politician': 12,\n",
        "    'B-election': 13, 'I-election': 14,\n",
        "    'B-person': 15, 'I-person': 16,\n",
        "    'B-organisation': 17, 'I-organisation': 18,\n",
        "    'B-location': 19, 'I-location': 20,\n",
        "    'B-misc': 21, 'I-misc': 22,\n",
        "    'B-politicalparty': 23, 'I-politicalparty': 24,\n",
        "    'B-event': 25, 'I-event': 26,\n",
        "    'B-scientist': 27, 'I-scientist': 28,\n",
        "    'B-university': 29, 'I-university': 30,\n",
        "    'B-discipline': 31, 'I-discipline': 32,\n",
        "    'B-enzyme': 33, 'I-enzyme': 34,\n",
        "    'B-protein': 35, 'I-protein': 36,\n",
        "    'B-chemicalelement': 37, 'I-chemicalelement': 38,\n",
        "    'B-chemicalcompound': 39, 'I-chemicalcompound': 40,\n",
        "    'B-astronomicalobject': 41, 'I-astronomicalobject': 42,\n",
        "    'B-academicjournal': 43, 'I-academicjournal': 44,\n",
        "    'B-theory': 45, 'I-theory': 46,\n",
        "    'B-award': 47, 'I-award': 48,\n",
        "    'B-musicgenre': 49, 'I-musicgenre': 50,\n",
        "    'B-song': 51, 'I-song': 52,\n",
        "    'B-band': 53, 'I-band': 54,\n",
        "    'B-album': 55, 'I-album': 56,\n",
        "    'B-musicalartist': 57, 'I-musicalartist': 58,\n",
        "    'B-musicalinstrument': 59, 'I-musicalinstrument': 60,\n",
        "    'B-book': 61, 'I-book': 62,\n",
        "    'B-writer': 63, 'I-writer': 64,\n",
        "    'B-poem': 65, 'I-poem': 66,\n",
        "    'B-magazine': 67, 'I-magazine': 68,\n",
        "    'B-literarygenre': 69, 'I-literarygenre': 70,\n",
        "    'B-programlang': 71, 'I-programlang': 72,\n",
        "    'B-algorithm': 73, 'I-algorithm': 74,\n",
        "    'B-metrics': 75, 'I-metrics': 76,\n",
        "    'B-conference': 77, 'I-conference': 78\n",
        "}\n"
      ],
      "metadata": {
        "id": "90Gqtk1vXJQv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq_kP5kO8Og7",
        "outputId": "98e784af-d9a6-408f-fde8-cab360e1713c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Capstone Project Data/DAPT_Checkpoint'\n",
        "model = BertForTokenClassification.from_pretrained(model_path, num_labels=79)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "LRR4QZGwdTOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1184193-399f-4169-a6ca-304a306a5165"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Capstone Project Data/DAPT_Checkpoint and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NERDataset(Dataset):\n",
        "    def __init__(self, tokenizer, file_paths, label_map):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_map = label_map\n",
        "        self.encodings = {'input_ids': [], 'attention_mask': []}\n",
        "        self.labels = []\n",
        "\n",
        "        # Process each file and populate texts and labels\n",
        "        for file_path in file_paths:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                tokens = []\n",
        "                tag_labels = []\n",
        "                for line in file:\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        if tokens:\n",
        "                            self.process_sentence(tokens, tag_labels)\n",
        "                            tokens, tag_labels = [], []\n",
        "                        continue\n",
        "                    if line.startswith(\"-DOCSTART-\"):\n",
        "                        continue\n",
        "\n",
        "                    # Handle splitting of tokens and tags\n",
        "                    parts = line.split()\n",
        "                    if len(parts) == 2:\n",
        "                        token, tag = parts\n",
        "                        tokens.append(token)\n",
        "                        tag_labels.append(tag)\n",
        "                    else:\n",
        "                        print(f\"Skipping malformed line: {line}\")\n",
        "                if tokens:  # Process any remaining sentence\n",
        "                    self.process_sentence(tokens, tag_labels)\n",
        "\n",
        "    def process_sentence(self, tokens, tag_labels):\n",
        "        encodings = self.tokenizer(tokens, is_split_into_words=True, truncation=True, padding='max_length', max_length=128, return_attention_mask=True, return_tensors='pt')\n",
        "        input_ids = encodings['input_ids'][0]\n",
        "        attention_mask = encodings['attention_mask'][0]\n",
        "\n",
        "        # Initialize labels tensor for input_ids with a default ignore index (-100)\n",
        "        labels = torch.full(input_ids.shape, fill_value=-100, dtype=torch.long)\n",
        "\n",
        "        # Get word ids for mapping tokens to their word origins\n",
        "        word_ids = encodings.word_ids(batch_index=0)\n",
        "\n",
        "        previous_word_idx = None\n",
        "        current_label_idx = self.label_map['O']\n",
        "        for token_idx, word_idx in enumerate(word_ids):\n",
        "            if word_idx is None:\n",
        "                continue\n",
        "            if word_idx != previous_word_idx:\n",
        "                if word_idx < len(tag_labels):\n",
        "                    current_label_idx = self.label_map.get(tag_labels[word_idx], self.label_map['O'])\n",
        "            labels[token_idx] = current_label_idx\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        self.encodings['input_ids'].append(input_ids)\n",
        "        self.encodings['attention_mask'].append(attention_mask)\n",
        "        self.labels.append(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.encodings['input_ids'][idx],\n",
        "            'attention_mask': self.encodings['attention_mask'][idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "8HwG2bKQdTL8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your training files\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/Capstone Project Data/English NER data (Domains)/ai/train.txt',\n",
        "    '/content/drive/MyDrive/Capstone Project Data/English NER data (Domains)/literature/train.txt',\n",
        "    '/content/drive/MyDrive/Capstone Project Data/English NER data (Domains)/music/train.txt',\n",
        "    '/content/drive/MyDrive/Capstone Project Data/English NER data (Domains)/politics/train.txt',\n",
        "    '/content/drive/MyDrive/Capstone Project Data/English NER data (Domains)/science/train.txt'\n",
        "]\n",
        "\n",
        "dataset = NERDataset(tokenizer, file_paths, label_map)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "6NBLuF7v-PZu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=0.2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Convert outputs to probabilities using softmax\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        # Create tensors for alpha and the gamma factor\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        at = self.alpha * (1 - pt) + (1 - self.alpha) * pt\n",
        "        F_loss = at * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return F_loss.mean()"
      ],
      "metadata": {
        "id": "WeI-sLwVwoK8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "69z5Kg9X8Np2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = FocalLoss(alpha=0.25, gamma=0.001)"
      ],
      "metadata": {
        "id": "Xm_mpE_k6YaZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "model.train()\n",
        "for epoch in range(25):  # Adjust the number of epochs if necessary\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch + 1}\")\n",
        "    for i, batch in progress_bar:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Reset gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Flatten the output for focal loss\n",
        "        active_labels = labels.view(-1)  # Flatten labels\n",
        "        active_logits = logits.view(-1, model.config.num_labels)  # Flatten logits\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(active_logits, active_labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix({'loss': total_loss / (i + 1)})\n",
        "\n",
        "    # Calculate the average loss for the epoch\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Average Loss = {average_loss:.4f}\")"
      ],
      "metadata": {
        "id": "zmydD6z0dTJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to disk\n",
        "model.save_pretrained('/content/drive/MyDrive/Capstone Project Data/Direct Fine-Tuning')\n",
        "\n",
        "# Save the tokenizer to disk\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/Capstone Project Data/Direct Fine-Tuning')\n",
        "\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg8pjGMvdTDV",
        "outputId": "24397a2a-4e5e-457a-a89f-2bc77f7c5d8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VpnbfY7EbUZP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yc1cvz1ubUWH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EM44fQ38bUTW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91uBDHenbUQq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g9dslC1vfeaJ"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}